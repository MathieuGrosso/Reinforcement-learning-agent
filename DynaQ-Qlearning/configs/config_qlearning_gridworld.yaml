env: gridworld-v0                                                                     # environnement
map: gridworldPlans/plan5.txt                                                         # carte a charger
rewards:                                                                              # rewards de l'environnement
  0: -0.001
  3: 1
  4: 1
  5: -1
  6: -1
seed: 5                                                                               # graine aleatoire
freqSave: 1000                                                                        # frequence de sauvegarde du modèle
freqTest: 100                                                                          # frequence de test
nbTest: 1                                                                             # nb de tests à effectuer tous les freqTest trajectoires
freqVerbose: 1000                                                                       # frequence d'affichage de l'environnement

nbModelSamples : 500
nbEpisodes: 100000
maxLengthTest: 500                                                                    # Longueur maxi des trajectoires en Test
maxLengthTrain: 400                                                                 # Longueur maxi des trajectoires en Train

exploMode: 1 # Mode d'exploration. 0 = epsilon-greedy (les autres a regarder je sais plus)
explo: 0.7                                                                         # coefficient d'exploration initial
alpha_r: 0.4
decay: 0.99                                                                        # a la fin de chaque trajectoire, le coefficient d'explo est multiplié par ce facteur
tau : 0.005
gamma: 0.99                                                                           # Facteur de discount
learningRate: 0.001                                                                     # Pas d'apprentissage
eligibility: 0                                                                        # coefficient d'eligibilité (le lambda du Q(lambda))
eligibilityThreshold: 0                                                               # en dessous de ce niveau de score d'eligibilité on coupe (pour aller plus vite)
sarsa: false                                                                          # si true = sarsa, sinon qlearning                                                                    # si > 0, dynaQ avec nbModelSamples echantillons issus du modèle apres chaque evenement
algorithm : 'Sarsa'
execute: |                                                                              # a executer apres le chargement de l'environnement
    env.setPlan(config["map"], config["rewards"])